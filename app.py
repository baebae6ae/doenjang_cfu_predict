# app.py (history + ontology í†µí•© ë²„ì „)
import streamlit as st
import pandas as pd
import pickle
from utils.preprocess import transform_preprocess
from env_model.env_inference import load_env_model, predict_env_effect, growth_multiplier_from_rate
from utils.history import PredictionHistory
from utils.postprocess import apply_scurve_adjustment
from utils import ontology as ontology_mod
import os
import numpy as np
from datetime import datetime
from utils.ontology_rules import OntologyRuleManager

st.set_page_config(page_title="ì½©ëœì¥ ìˆ™ì„±ë¬¼ Bacillus cereus ì¦ì‹ ì˜ˆì¸¡", layout="wide")
st.title("ì½©ëœì¥ ìˆ™ì„±ë¬¼ Bacillus cereus ì¦ì‹ ì˜ˆì¸¡ ì•± (Env + records + History + Ontology)")

# ---- model loading ----
MODEL_PATH = "model/cfu_model_retrained.pkl"
ENV_MODEL_PATH = "models/env_model_v1.pkl"

if not os.path.exists(MODEL_PATH):
    st.error(f"ë©”ì¸ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
    st.stop()

with open(MODEL_PATH, "rb") as f:
    saved = pickle.load(f)
model = saved.get("model")
scaler = saved.get("scaler")
feature_columns = saved.get("feature_columns", [])
meta = saved.get("meta", {})
saved_num_cols = meta.get("num_cols") if meta else None

env_pipeline = None
if os.path.exists(ENV_MODEL_PATH):
    env_pipeline = load_env_model(ENV_MODEL_PATH)

# ---- history manager init ----
history = PredictionHistory(db_path="data/predictions.db")

# ---- navigation ----
mode = st.sidebar.radio("ëª¨ë“œ ì„ íƒ", ["Predict", "History", "Ontology"])

# ---------------- PREDICT ----------------
if mode == "Predict":
    st.header("CFU ì˜ˆì¸¡")
    with st.form("predict_form"):
        col1, col2, col3 = st.columns(3)
        with col1:
            moisture = st.number_input("ìˆ˜ë¶„ (%)", 30.0, 70.0, 50.0)
            salt = st.number_input("ì—¼ë„ (%)", 5.0, 20.0, 12.0)
            initial_cfu = st.number_input("ì´ˆê¸° Bacillus cereus ê· ìˆ˜ (CFU/g)", 0, 1000000, 5000)
            period = st.number_input("ìˆ™ì„± ê¸°ê°„ (ì¼)", 1, 365, 30)
            month = st.number_input("ìˆ™ì„± ì‹œì‘ ì›”", 1, 12, 6)
        with col2:
            temp = st.number_input("ìˆ™ì„± ì˜¨ë„ (Â°C) (ì„ íƒ)", 0.0, 60.0, value=float("nan"), step=0.1, format="%.1f")
            humidity = st.number_input("ìˆ™ì„± ìŠµë„ (%) (ì„ íƒ)", 0.0, 100.0, value=float("nan"), step=0.1, format="%.1f")
            aw = st.number_input("ìˆ˜ë¶„í™œì„±ë„ (a_w) (ì„ íƒ)", 0.0, 1.00, value=float("nan"), step=0.01, format="%.3f")
        with col3:
            pH = st.number_input("pH", 3.0, 8.5, 6.2)
            tank = st.number_input("íƒ±í¬ ìˆœì„œ", 1, 50, 1)
            notes = st.text_input("ë©”ëª¨ (ì„ íƒ)")
        use_lit = st.checkbox("ë¬¸í—Œê¸°ë°˜ ë³´ì • ì‚¬ìš© (env ê°’ ë¯¸ì…ë ¥ ì‹œ ëŒ€ì²´/ë³´ì •)", value=True)
        submitted = st.form_submit_button("CFU ì˜ˆì¸¡")
    if submitted:
        # env handling
        if not (np.isfinite(temp) and np.isfinite(humidity) and np.isfinite(aw)) and env_pipeline is not None and use_lit:
            med_temp = 25.0 if np.isnan(temp) else temp
            med_RH = 80.0 if np.isnan(humidity) else humidity
            med_aw = 0.95 if np.isnan(aw) else aw
            predicted_rate = predict_env_effect(env_pipeline, med_temp, med_RH, med_aw, pH, "soybean_paste", initial_cfu)
            multiplier_30d = growth_multiplier_from_rate(predicted_rate, hours=24*30, initial_cfu=initial_cfu)
            st.info(f"ë¬¸í—Œê¸°ë°˜ ì˜ˆì¸¡ ì„±ì¥ë¥ (ì‹œê°„ë‹¹ lnë¹„): {predicted_rate:.6f}")
        elif env_pipeline is not None:
            predicted_rate = predict_env_effect(env_pipeline, temp, humidity, aw, pH, "soybean_paste", initial_cfu)
            multiplier_30d = growth_multiplier_from_rate(predicted_rate, hours=24*30, initial_cfu=initial_cfu)
            st.info(f"ì…ë ¥ê°’ ê¸°ë°˜ ì˜ˆì¸¡ ì„±ì¥ë¥ (ì‹œê°„ë‹¹ lnë¹„): {predicted_rate:.6f}")
        else:
            predicted_rate = 0.0
            multiplier_30d = 1.0

        input_dict = {
            "moisture": moisture, "salt": salt, "initial_cfu": initial_cfu,
            "period": period, "pH": pH, "tank": tank, "temp": temp, "humidity": humidity, "aw": aw
        }

        # build dataframe for main model: include env features
        input_df = pd.DataFrame([{
            "moisture": moisture, "salt": salt, "initial_cfu": initial_cfu,
            "period": period, "month": month, "pH": pH, "tank": tank,
            "env_pred_rate_per_hour": predicted_rate, "env_multiplier_30d": multiplier_30d
        }])

        # transform via preprocess
        try:
            input_processed = transform_preprocess(input_df, scaler=scaler, feature_columns=feature_columns, saved_num_cols=saved_num_cols)
        except KeyError as e:
            st.error(f"Preprocessing error: {e}. Check model/feature mismatch.")
            st.stop()

        pred_cfu = model.predict(input_processed)[0]

        # Phase 3 ë³´ì • ì ìš©
        pred_cfu_adj = apply_scurve_adjustment(pred_cfu)

        # Phase 4: Ontology ê¸°ë°˜ ë³´ì • ì ìš©
        try:
            # ë£° ë§¤ë‹ˆì € ì´ˆê¸°í™”
            rule_manager = OntologyRuleManager()

            # History DB ë¶ˆëŸ¬ì˜¤ê¸°
            df_hist = history.list_predictions(limit=1000)
            df_hist = df_hist.dropna(subset=["actual_final_cfu"])
            df_hist = df_hist[df_hist["verified"] == 1]

            if not df_hist.empty:
                rules = rule_manager.extract_rules(df_hist)
                factor = rule_manager.apply_rules(input_dict)
                pred_cfu_final = pred_cfu * factor
                st.success(f"Ontology ë£° ì ìš© ìµœì¢… ì˜ˆì¸¡: {pred_cfu_final:.0f} CFU/g")
                if rules:
                    st.info(f"ì ìš©ëœ ë£° ê°œìˆ˜: {len(rules)}")
            else:
                pred_cfu_final = pred_cfu
                st.warning("ê²€ì¦ëœ íˆìŠ¤í† ë¦¬ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ Ontology ë£° ì ìš© ë¶ˆê°€")
        except Exception as e:
            pred_cfu_final = pred_cfu
            st.error(f"Ontology ë£° ì ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        st.success(f"ML ëª¨ë¸ ì¶œë ¥ê°’: {pred_cfu:.0f} CFU/g")
        st.success(f"S-curve ë³´ì •ê°’: {pred_cfu_adj:.0f} CFU/g")
        st.write(f"í™˜ê²½ ê¸°ë°˜ multiplier(30d): {multiplier_30d:.3f}")

        # save to history
        rec_id = history.save_prediction(inputs=input_dict, predicted_cfu=float(pred_cfu_final),
                                         env_pred_rate=float(predicted_rate), env_multiplier=float(multiplier_30d),
                                         predicted_hours=24*30, model_path=MODEL_PATH, notes=notes)
        st.info(f"ì˜ˆì¸¡ ì´ë ¥ì— ì €ì¥ë¨ (id={rec_id}). 'History' íƒ­ì—ì„œ ì‹¤ì œê°’ì„ ì¶”ê°€/ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ---------------- HISTORY ----------------
elif mode == "History":
    st.header("ì˜ˆì¸¡ ì´ë ¥ (Predictions History)")
    df = history.list_predictions(limit=500)
    if df.empty:
        st.info("ì €ì¥ëœ ì˜ˆì¸¡ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.dataframe(df[["id","timestamp","predicted_cfu","env_pred_rate","env_multiplier","actual_final_cfu","verified","model_version", "notes"]])
        sel = st.number_input("ìˆ˜ì •í•  ê¸°ë¡ ID ì…ë ¥ (ID)", value=int(df.iloc[0]["id"]), min_value=int(df["id"].min()), max_value=int(df["id"].max()))
        if st.button("ì„ íƒí•œ ê¸°ë¡ ì‚­ì œ"):
            history.delete(int(sel))
            st.success(f"ë ˆì½”ë“œ {sel} ì‚­ì œ ì™„ë£Œ. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")
        rec = history.get_prediction(int(sel))
        if rec:
            st.subheader(f"ë ˆì½”ë“œ {sel} ìƒì„¸")
            st.json({
                "id": rec["id"],
                "timestamp": rec["timestamp"],
                "inputs": rec.get("inputs"),
                "predicted_cfu": rec.get("predicted_cfu"),
                "env_pred_rate": rec.get("env_pred_rate"),
                "env_multiplier": rec.get("env_multiplier"),
                "actual_final_cfu": rec.get("actual_final_cfu"),
                "actual_time_hours": rec.get("actual_time_hours"),
                "computed_growth_rate_per_hour": rec.get("computed_growth_rate_per_hour"),
                "verified": rec.get("verified"),
                "model_version": rec["model_version"],
                "notes": rec.get("notes")
            },expanded=False)
            st.markdown("### ì‹¤ì œ ê´€ì¸¡ê°’ ì…ë ¥ / ìˆ˜ì •")
            with st.form("actual_form"):
                act_final = st.number_input("ì‹¤ì œ ìµœì¢… CFU/g (actual_final_cfu)", value=rec.get("actual_final_cfu") or 0.0, step=1.0)
                act_time = st.number_input("ì‹¤ì œ ìˆ™ì„± ê¸°ê°„ (days)", value=(rec.get("actual_time_hours")/24.0) if rec.get("actual_time_hours") is not None else 1.0, step=1.0)
                add_note = st.text_input("ì¶”ê°€ ë©”ëª¨", value="")
                verify_flag = st.checkbox("í™•ì¸(verified)ìœ¼ë¡œ í‘œì‹œ", value=bool(rec.get("verified")))
                submit_actual = st.form_submit_button("ì €ì¥ (Update actual)")
            if submit_actual:
                history.update_actual(int(sel), actual_final_cfu=float(act_final), actual_time_hours=(float(act_time)*24.0),
                                      verified=1 if verify_flag else 0, notes=add_note)
                st.success("ì—…ë°ì´íŠ¸ ì™„ë£Œ. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ë©´ ë³€ê²½ëœ ê°’ì´ ë°˜ì˜ë©ë‹ˆë‹¤.")
            if st.button("Export history to CSV"):
                out = history.export_csv()
                with open(out, "rb") as f:
                    st.download_button("Download CSV", f, file_name=os.path.basename(out))
        else:
            st.error("í•´ë‹¹ ID ë ˆì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    import subprocess, shlex, sys

    if st.button("Retrain MainModel with verified history rows"):
        cmd = [
            sys.executable,
            "scripts/retrain_main_with_history.py",
            "--db", "data/predictions.db",
            "--main", "data/bacillus1.csv",
            "--out", "model/cfu_model_retrained.pkl"
        ]

        # í˜„ì¬ í™˜ê²½ ë³µì‚¬
        env = os.environ.copy()
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ PYTHONPATHì— ì¶”ê°€
        env["PYTHONPATH"] = os.getcwd()

        st.write("Running:", " ".join(cmd))
        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, env=env)
        for line in proc.stdout:
            st.write(line)
        proc.wait()
        if proc.returncode == 0:
            st.success("MainModel retrained with history and saved.")
        else:
            st.error("Retrain failed. See logs above.")

# ---------------- ONTOLOGY ----------------
elif mode == "Ontology":
    st.header("Ontology ê¸°ë°˜ í’ˆì§ˆ ê²€ì¦")
    st.markdown("Prediction historyë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì˜ˆì¸¡ ì„±ëŠ¥**ê³¼ **ì¡°ê±´ë³„ ì˜¤ì°¨ íŒ¨í„´**ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

    if st.button("Build & Analyze Ontology"):
        res = ontology_mod.build_graph(
            db_path=history.db_path,
            out_graphml="data/ontology.graphml",
            out_json="data/ontology.json",
            out_triples="data/ontology_triples.json"
        )

        # âœ… ì„±ëŠ¥ ìš”ì•½
        if res["perf"]:
            st.metric("ìƒ˜í”Œ ìˆ˜", res["perf"]["n_samples"])
            st.metric("RMSE", f"{res['perf']['rmse']:.2f}")
            st.metric("RÂ²", f"{res['perf']['r2']:.3f}")
        else:
            st.warning("ì‹¤ì¸¡ ë°ì´í„° ë¶€ì¡±")

        # ğŸ“Š ì˜ˆì¸¡ vs ì‹¤ì œ ë¹„êµ ì‚°ì ë„
        st.subheader("ì˜ˆì¸¡ vs ì‹¤ì œ ë¹„êµ")
        nodes_df = pd.DataFrame(res["node_link"]["nodes"])
        actuals = nodes_df[(nodes_df["type"]=="Measurement") & (nodes_df["mode"]=="actual")]
        preds   = nodes_df[(nodes_df["type"]=="Measurement") & (nodes_df["mode"]=="predicted")]
        if not actuals.empty and not preds.empty:
            df_comp = pd.DataFrame({
                "pred": preds["value"].astype(float).values[:len(actuals)],
                "actual": actuals["value"].astype(float).values,
                "sample": actuals["id"].str.replace("Measurement:Actual:","")
            })
            df_comp["error"] = df_comp["pred"] - df_comp["actual"]
            st.scatter_chart(df_comp[["pred","actual"]])

        # ğŸ“‘ Ontology Rule Report
        st.subheader("Ontology ë£° ë¦¬í¬íŠ¸ (ìë™ ì¶”ì¶œ)")
        try:
            mgr = OntologyRuleManager(min_samples=5, error_threshold=0.10, bins=4)
            df_hist = history.list_predictions(limit=2000)
            # keep rows with predicted and actual
            df_hist = df_hist.dropna(subset=["predicted_cfu", "actual_final_cfu"])
            # prefer verified rows if available
            if "verified" in df_hist.columns and df_hist["verified"].sum() >= mgr.min_samples:
                df_hist = df_hist[df_hist["verified"]==1]
            rules = mgr.extract_rules(df_hist)
            if rules:
                rules_df = pd.DataFrame(rules)
                st.dataframe(rules_df[["feature","type","repr","n_samples","mean_error","rel_error","factor"]])
                st.markdown("#### ì¶”ì²œ í•´ì„")
                for r in rules:
                    sign = "ì¦ê°€" if r["factor"]>1 else "ê°ì†Œ"
                    st.markdown(f"- `{r['repr']}`: ìƒ˜í”Œìˆ˜={r['n_samples']}, í‰ê· ì˜¤ì°¨={r['mean_error']:.1f}, ìƒëŒ€ì˜¤ì°¨={r['rel_error']:.2%} â†’ **{sign} {abs(1-r['factor']):.2%}**")
            else:
                st.info("ì¶”ì¶œëœ ë£°ì´ ì—†ìŠµë‹ˆë‹¤ (ë°ì´í„° ë¶€ì¡± ë˜ëŠ” ì˜¤ì°¨ ì„ê³„ì¹˜ ë¯¸ë‹¬).")

        except Exception as e:
            st.error("Ontology ë£° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: " + str(e))

        # ğŸ“Š Feature Importance (ì§ê´€ì  í•´ì„ìš©)
        st.subheader("Feature Importance (ëª¨ë¸ì´ ì¤‘ìš”í•˜ê²Œ ë³´ëŠ” ìš”ì¸)")

        try:
            if hasattr(model, "feature_importances_") and feature_columns:
                importances = model.feature_importances_
                fi_df = pd.DataFrame({
                    "Feature": feature_columns,
                    "Importance": importances
                }).sort_values("Importance", ascending=False)

                # âŒ ë¶ˆí•„ìš”í•œ ì›ë³¸ í™˜ê²½ ë³€ìˆ˜ ì œê±° (main ëª¨ë¸ì—ëŠ” ì˜ë¯¸ ì—†ìŒ)
                drop_feats = ["temp", "humidity", "aw"]
                fi_df = fi_df[~fi_df["Feature"].isin(drop_feats)]

                # âœ… í™˜ê²½ ë³€ìˆ˜ ë§¤í•‘ ì‚¬ì „
                feature_map = {
                    "env_pred_rate_per_hour": "í™˜ê²½ ê¸°ë°˜ ì˜ˆì¸¡ ì„±ì¥ë¥  (temp, humidity, aw ë°˜ì˜)",
                    "env_multiplier_30d": "í™˜ê²½ ê¸°ë°˜ ì¦ì‹ ë°°ìˆ˜ (30ì¼ ê¸°ì¤€, temp, humidity, aw ë°˜ì˜)"
                }

                # í•´ì„ìš© ì»¬ëŸ¼ ì¶”ê°€
                fi_df["Interpretation"] = fi_df["Feature"].map(feature_map).fillna(fi_df["Feature"])

                # Plotlyë¡œ ë³´ê¸° ì¢‹ê²Œ ì‹œê°í™” (ë¼ë²¨ ìˆ˜í‰ ì •ë ¬)
                import plotly.express as px
                fig = px.bar(
                    fi_df.sort_values("Importance", ascending=True),
                    x="Importance",
                    y="Interpretation",
                    orientation="h",
                    title="Feature Importance (í•´ì„ í¬í•¨)"
                )
                st.plotly_chart(fig, use_container_width=True)

                st.write("- ìˆ˜ì¹˜ê°€ ë†’ì„ìˆ˜ë¡ í•´ë‹¹ ë³€ìˆ˜ê°€ Bacillus cereus ì¦ì‹ ì˜ˆì¸¡ì— ë” í° ì˜í–¥ì„ ì¤ë‹ˆë‹¤.")
            else:
                st.info("ëª¨ë¸ì—ì„œ Feature Importanceë¥¼ ì§€ì›í•˜ì§€ ì•Šê±°ë‚˜ feature_columns ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error("Feature Importance í‘œì‹œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: " + str(e))